{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELISATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour répondre à notre problématique, nous implémentons deux modèles de machine learning : Random Forest et XGBoost.\n",
    "\n",
    "Enfin, nous allons utiliser des modèles de machine learning pour prédire le genre d'une musique grâce aux variables dont nous disposons. Nous utilisons d'abord un modèle de type Random Forest, puis un modèle de type XGBoost, pour finalement comparer les deux.\n",
    "\n",
    "Nous avons réalisé cette partie à partir des articles de Ilyes TALBI, Samir JEETO et Valentin DORE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour la récupération des données\n",
    "import pandas as pd\n",
    "\n",
    "#Pour la visualisation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Pour la modélisation\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, validation_curve, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, f1_score, zero_one_loss, classification_report\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/tlaflotte/genre_detector/spotify_tracks_cleaned.csv\"\n",
    "\n",
    "df = pd.read_csv(\"https://minio.lab.sspcloud.fr\" + file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, nous séparons la variable à prédire (le genre) des autres variables (les features). Ensuite, nous séparons ces ensembles en deux parties, l'une pour entraîner le modèle et l'autre pour tester le modèle. Comme notre base de données est ordonnée par genre, nous indiquons qu'il faut bisséquer aléatoirement cette base de données avec l'argument shuffle=True.\n",
    "\n",
    "Nous pourrions enlever des variables puisque notre étape de visualisation a mis en évidence de fortes corrélations entre certaines d'entre elles. Cela ferait gagner du temps, pour un petit peu moins de précision. Nous avons choisi de garder toutes nos variables car le temps de calcul n'est pas très long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'genre'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'genre'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m features \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# isolation of the feature to predict\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m genres \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgenre\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      5\u001b[0m features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenre\u001b[39m\u001b[38;5;124m'\u001b[39m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m feature_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(features\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'genre'"
     ]
    }
   ],
   "source": [
    "features = df.copy()\n",
    "\n",
    "# isolation of the feature to predict\n",
    "genres = np.array(features['genre'])\n",
    "features = features.drop('genre', axis = 1)\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "\n",
    "# separation in training and testing sets\n",
    "train_features, test_features, train_genres, test_genres = train_test_split(features, genres, test_size = 0.25, random_state = 0, shuffle = True)\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Genres Shape:', train_genres.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Genres Shape:', test_genres.shape)\n",
    "\n",
    "# reshaping\n",
    "sc = StandardScaler()\n",
    "train_features = sc.fit_transform(train_features)\n",
    "test_features = sc.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning des hyper-paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintentant, nous allons procéder au tuning des hyper-paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state = 0)\n",
    "\n",
    "print('Parameters currently in use:\\n')\n",
    "print(rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a bien trop d'hyper-paramètres sur lesquels nous pouvons jouer. Nous choisissons de jouer sur 8 d'entre eux tels que le nombre d'arbres, la profondeur maximale des arbres ou encore le nombre minimal d'échantillons par nœuds.\n",
    "\n",
    "Nous n'avons pas indiqué des poids pour chaque genre, car la base de données est relativement équilibrée. Pour améliorer le modèle, nous pourrions mettre des poids à chaque genre pour avoir une base de données parfaitement équilibrée.\n",
    "\n",
    "Voici, les valeurs pour lesquelles nous allons tester les performances du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un classifieur Random Forest\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Définir l'espace de recherche pour chaque hyperparamètre\n",
    "param_dist = {\n",
    "    'n_estimators': np.random.randint(100, 1000),  # entre 100 et 1000 arbres\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],  # Profondeur des arbres\n",
    "    'min_samples_split': np.random.randint(2, 20),  # Entre 2 et 20 échantillons pour diviser un noeud\n",
    "    'min_samples_leaf': np.random.randint(1, 20),  # Entre 1 et 20 échantillons par feuille\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],  # Nombre de caractéristiques à essayer\n",
    "    'bootstrap': [True, False],  # Utiliser le bootstrap ou non\n",
    "    'ccp_alpha': np.random.uniform(0.0, 0.1),  # Paramètre pour la coupe des arbres (complexité)\n",
    "    'max_samples': [None, 0.8, 0.9],  # Fraction d'échantillons à utiliser pour chaque arbre\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous utilisons `RandomizedSearchCV` pour rechercher dans l'espace de recherche pour chaque hyperparamètre de manière aléatoire. Il y a un paramètre clé ici : le nombre d'itérations (nombre de combinaisons d'hyperparamètres à tester). Plus le nombre d'itérations est élevé, plus la recherche a de chances de trouver une bonne combinaison, mais cela prend plus de temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# creation of the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rf \u001b[38;5;241m=\u001b[39m \u001b[43mRandomForestClassifier\u001b[49m(random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, max_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m'\u001b[39m, bootstrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# random search\u001b[39;00m\n\u001b[1;32m      5\u001b[0m rf_random \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(estimator \u001b[38;5;241m=\u001b[39m rf, param_distributions \u001b[38;5;241m=\u001b[39m random_grid, n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Définir la recherche aléatoire avec un nombre d'itérations (par exemple, 100)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,  # Le modèle à entraîner\n",
    "    param_distributions=param_dist,  # L'espace de recherche\n",
    "    n_iter=100,  # Nombre d'itérations de la recherche\n",
    "    scoring='accuracy',  # Critère d'évaluation (par exemple, l'exactitude)\n",
    "    cv=5,  # Validation croisée (par exemple, 5-fold)\n",
    "    verbose=1,  # Afficher les informations pendant l'exécution\n",
    "    n_jobs=-1,  # Utiliser tous les cœurs du processeur pour accélérer le calcul\n",
    "    random_state=0  # Garantir la reproductibilité des résultats\n",
    ")\n",
    "\n",
    "# Lancer la recherche\n",
    "random_search.fit(train_features, train_genre)\n",
    "\n",
    "# Résultats des meilleurs hyperparamètres trouvés\n",
    "print(\"Meilleurs hyperparamètres :\", random_search.best_params_)\n",
    "print(\"Meilleure performance (score) :\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois la recherche terminée, on peut accéder aux meilleurs hyperparamètres trouvés et à la performance correspondante via `random_search.best_params_` et `random_search.best_score_` qui renvoient respectivement les meilleurs hyperparamètres trouvés par la recherche et la performance (ici l'accuracy) du modèle avec ces meilleurs hyperparamètres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons donc fini la partie du tuning des hyper-paramètres, et nous pouvons alors lancer le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lancement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# creation of the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rf \u001b[38;5;241m=\u001b[39m \u001b[43mRandomForestClassifier\u001b[49m(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4000\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m'\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, bootstrap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgini\u001b[39m\u001b[38;5;124m'\u001b[39m ,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# fit\u001b[39;00m\n\u001b[1;32m      5\u001b[0m rf\u001b[38;5;241m.\u001b[39mfit(train_features, train_genres)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Créer un nouveau classifieur Random Forest avec les meilleurs hyperparamètres\n",
    "optimized_rf = RandomForestClassifier(**best_params, random_state=0)\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "optimized_rf.fit(train_features, train_genre)\n",
    "\n",
    "# prédictions\n",
    "predictions = optimized_rf.predict(test_features)\n",
    "\n",
    "# Zero_one_loss error\n",
    "errors = zero_one_loss(test_genres, predictions, normalize=True)\n",
    "print('zero_one_loss error normalized:', errors)\n",
    "\n",
    "# Accuracy Score\n",
    "accuracy_test = accuracy_score(test_genres, predictions)\n",
    "print('accuracy_score on test dataset :', accuracy_test)\n",
    "\n",
    "print(classification_report(predictions, test_genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons une précision de 65% ce qui est satisfaisant !\n",
    "\n",
    "On remarque que les genres les mieux prédits sont bien classical music et rap, comme nous l'avions attendu grâce à notre étape de visualisation. De plus, les genres rock, r&b et encore pop sont moins bien identifés comme nous l'attendions également.\n",
    "\n",
    "Nous traçons la matrice de confusion pour visualiser les différentes erreurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Confusion matrix\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m(test_genres, predictions)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(mat, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#plt.colorbar(label='Valeurs')\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "\n",
    "mat = confusion_matrix(test_genres, predictions)\n",
    "plt.imshow(mat, cmap='viridis', interpolation='nearest')\n",
    "#plt.colorbar(label='Valeurs')\n",
    "plt.title('Matrice de Confusion')\n",
    "num_rows, num_cols = mat.shape\n",
    "for i in range(num_rows):\n",
    "    for j in range(num_cols):\n",
    "        plt.text(j, i, str(mat[i, j]), ha='center', va='center', color='w', fontsize=12)\n",
    "plt.grid(False)\n",
    "genres_list = ['edm','latin','pop','r&b','rap','rock']\n",
    "plt.xticks(np.arange(num_cols), genres_list, rotation=45, ha='right')\n",
    "plt.yticks(np.arange(num_rows), genres_list)\n",
    "plt.xlabel('true genre')\n",
    "plt.ylabel('predicted genre')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grâce à la matrice des confusions, nous pouvons voir par exemple que les musiques classiques sont bien classés, sauf quelques unes qui sont évaluées comme des musiques jazz : c'est exactement ce que notre étape de visualisation avait annoncé !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Feature importances\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfivethirtyeight\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m importances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(rf\u001b[38;5;241m.\u001b[39mfeature_importances_)\n\u001b[1;32m      6\u001b[0m x_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(importances)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "#Feature importances\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "importances = list(rf.feature_importances_)\n",
    "\n",
    "x_values = list(range(len(importances)))\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous traçons ici l'importance de chaque variable. Nous observons que key, mode et time_signature ne sont pas très utiles à la prédiction. Nous pouvions nous y attendre puisque ce sont des variables qui varient relativement peu, et qui sont décorrélées de chaque genre.\n",
    "\n",
    "Ainsi, notre modélisation Random Forest permet de prédire un genre musical avec une précision de 66%, ce qui est satisfaisant, mais en réalité elle identifie mal les genres pop et rock qui sont très représentés dans le monde de la musique, tandis qu'elle identifie bien le genre classical music, qui n'est pas le genre le plus écouté de nos jours."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
