{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook présente une approche pour déterminer le genre d'une musique à travers les caractéristiques fournies par l'API spotify en utilisant des algorithmes de Machine Learning. Ce projet s'intègre dans le cadre du cours Python pour la Data Science de l'ENSAE Paris. Il a été mené par Tom Laflotte, Enzo Moran et Martin Conte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il suit le plan suivant:\n",
    "\n",
    "I. Une première approche via l'API Spotify\n",
    "\n",
    "1. Collecte des données\n",
    "\n",
    "    a. Constitution d'un premier dataset\n",
    "    \n",
    "    b. Collecte du genre des artistes\n",
    "\n",
    "2. Visualisation\n",
    "\n",
    "II. Prédiction à l'aide d'une base de données Kaggle \n",
    "\n",
    "1. Préparation des données\n",
    "\n",
    "    a. Gestion des valeurs\n",
    "\n",
    "    b. Standardisation des variables continues\n",
    "\n",
    "    c. Imputation des valeur manquantes\n",
    "\n",
    "    d. Imputation des variables catégorielles *\n",
    "\n",
    "2. Visualisation des données préparées\n",
    "\n",
    "    a. Analyse multivariée\n",
    "\n",
    "    b.Vérification du poids des variables\n",
    "\n",
    "3. Modélisation\n",
    "    a. Random Forest\n",
    "\n",
    "    b. XGBoost\n",
    "\n",
    "    c. Catboost\n",
    "\n",
    "Conclusion\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spotipy\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import csv\n",
    "import time\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    validation_curve,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    zero_one_loss,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    ")\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Une première approche via l'API Spotify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord nous devons importer toutes les librairies qui nous seront nécessaires pour cette partie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.1. Collecte des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons d'abord essayé de créer une base de données grâce à l'API Spotify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1.a. Constitution d'un premier dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spotify ne met pas à disposition une quelconque base de donnée déjà constituée. Nous allons donc devoir faire des requêtes successives à l'API pour récolter les informations sur les morceaux choisis, afin de constituer notre premier dataset. Chaque requête permet d'obtenir les metadonnées d'un artiste donné, ou d'une playlist donnée. C'est ce que nous avons choisi de faire.\n",
    "\n",
    "Pour minimiser le nombre de requêtes, nous sélectionnons une playlist de 10 000 morceaux déjà faite par un utilisateur Spotify, afin d'obtenir des informations sur chaque morceau qui la compose : titre, id, artist, artist_id. Ensuite, nous récupérons les informations qui nous intéressent sur chaque morceau : les track features, qui sont un tas d'indices quantitatifs Enfin, nous récupérons le genre qui n'est associé qu'à l'artiste, et pas au morceau. C'est ici une limite préoccupante : le genre qui est la variable à prédire n'est en fait que le genre de l'artiste et pas le genre véritable du morceau.\n",
    "\n",
    "D'abord, on initialise le client Spotify pour l'obtention des données via l'API grâce au token d'accès."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spotify_client():\n",
    "    \"\"\"\n",
    "    Initialize the Spotify API client with client credentials.\n",
    "    Returns an authenticated Spotify client.\n",
    "    \"\"\"\n",
    "    return spotipy.Spotify(auth_manager=SpotifyClientCredentials(\n",
    "        client_id=\"d666ee3ae4c94b85945c3dba39776f4f\",\n",
    "        client_secret=\"c1973a77acbe48c0b2f105e4f57d7d46\" \n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous utilisons ce client pour notre requête sur la playlist de 10 000 morceaux.\n",
    "\n",
    "Nous entrons l'id de la playlist en question. Nous récupérons les informations de la playlist relatives aux morceaux dans get_all_playlist_tracks. Avec les informations obtenues précédemment, nous créons avec get_track_id_and_artist un dataframe qui pour chaque morceau de la playlist en donne le titre, l'id, l'artist, l'artist id.\n",
    "\n",
    "Notre objectif final est d'obtenir un fichier csv compilant toutes les données fournies par l'API de Spotify dans un fichier csv.\n",
    "Voici la fonction réalisant cette tache :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlists_data_to_csv(playlist_ids):\n",
    "    \"\"\"This function allows to fetch the data from different playlists into a csv\n",
    "    Params:\n",
    "        - playlist_ids: a list of playlists we want to fetch our data from\n",
    "    \"\"\"\n",
    "    names=[]\n",
    "    track_data=[]\n",
    "    file_name=''\n",
    "    for playlist in playlist_ids: \n",
    "        print(f\"Fetching playlist {playlist} tracks...\")\n",
    "        tracks = fetch_playlist_tracks(playlist)\n",
    "        print(\"Fetching track data...\")\n",
    "        track_data+=(fetch_track_data(tracks))\n",
    "    for id in playlist_ids:\n",
    "        names.append(spotify_client().playlist(id)['name'])\n",
    "    for name in names:\n",
    "        file_name+=name+'+'\n",
    "    file_name=file_name[:-1]\n",
    "    print(file_name)\n",
    "    if track_data:\n",
    "        save_to_csv(track_data, f\"playlists_{file_name}_data.csv\")\n",
    "    else:\n",
    "        print(\"No data to save.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Détaillons cette fonction, la fonction fetch_playlist_tracks est définie ci-dessous permet l'obtention d'informations identifiant l'ensemble des musiques d'une playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_playlist_tracks(playlist_id):\n",
    "    \"\"\"\n",
    "    Fetch all tracks from a Spotify playlist. \n",
    "    Params:\n",
    "        -playlist_id: Spotify playlist ID.\n",
    "    Returns a list of dictionaries containing track details.\n",
    "    \"\"\"\n",
    "    tracks = []\n",
    "    results = spotify_client().playlist_tracks(playlist_id)\n",
    "    while results:\n",
    "        for item in results['items']:\n",
    "            track = item['track']\n",
    "            if track:  # Ensure the track is not None\n",
    "                tracks.append(track)\n",
    "        results = spotify_client().next(results) if results['next'] else None\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut également obtenir le genre de l'artiste que nous assimilerons dans un premier temps à celui de la musique. Ici, nous ne sélectionnons que le genre principal de l'artiste pour plus de simplicité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_artist_genre(track):\n",
    "    \"\"\"This function fetches the genre of an artist with a track from this artist, it will be \n",
    "    considerated as the genre of the song later\n",
    "\n",
    "    Args:\n",
    "        track a dict the countains infos about the track\n",
    "\n",
    "    Returns: genre a string that is the genre of an artist\n",
    "        \n",
    "    \"\"\"\n",
    "    artist=track['artists'][0]['id']\n",
    "    if spotify_client().artist(artist)['genres'] != []:\n",
    "        return spotify_client().artist(artist)['genres'][0]\n",
    "    else:\n",
    "        return 'N/A'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut alors obtenir l'ensemble des informations relatives à chaque musique utiles à l'analyse (dansabilité, tempo...) via la fonction `fetch_track_data`. Du fait des restrictions de requêtes imposées par l'API de spotify, nous avons mis en place des requêtes par paquets de 100 chansons suivi d'une pause d'une minute, cette approche nous a permis de constituer une première base de données de 1500 musiques, en répétant ce procédé sur une plus longue période, il serait possible d'obtenir les données de l'ensemble de la playlist mais comme nous le détaillerons plus tard, nous n'avons pas retenu cette approche et nous contenterons de la base de données intermédiaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_track_data(tracks):\n",
    "    \"\"\"\n",
    "    Fetch metadata and audio features for each track in the playlist.\n",
    "    Params:\n",
    "        -tracks: List of tracks from the playlist.\n",
    "    Returns a list of dictionaries containing track metadata and audio features.\n",
    "    \"\"\"\n",
    "    track_data = []\n",
    "    i=0\n",
    "    j=0\n",
    "    for track in tracks:\n",
    "        track_id = track['id']\n",
    "        i+=1\n",
    "        print(i)\n",
    "        audio_features = spotify_client().audio_features([track_id])[0]\n",
    "        genre=fetch_artist_genre(track)\n",
    "        if audio_features: \n",
    "            artist_name = \", \".join([artist['name'] for artist in track['artists']])\n",
    "            dict_track={\"track Name\": track['name'],\n",
    "                \"artists\": artist_name,\n",
    "                \"track_id\": track_id,\n",
    "                \"popularity\": track['popularity'],\n",
    "                \"duration_ms\": track['duration_ms'],\n",
    "                \"explicit\": track['explicit'], 'genre': genre}\n",
    "            for key in audio_features.keys():\n",
    "                dict_track[key]=audio_features[key]\n",
    "            track_data.append(dict_track)\n",
    "        if i==100:\n",
    "            j+=1\n",
    "            save_to_csv(track_data, f\"intermédiaire{j}\")\n",
    "            i=0\n",
    "            time.sleep(60)\n",
    "    return track_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il ne reste plus qu'à sauvegarder le tout au format csv: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data, filename):\n",
    "    \"\"\"\n",
    "    Save the list of track data to a CSV file.\n",
    "    Params:\n",
    "    :param data: List of dictionaries containing track details.\n",
    "    :param filename: Output CSV file name.\n",
    "    \"\"\"\n",
    "    keys = data[0].keys() if data else []\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "    print(f\"Data saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La requête suivante permet de constituer un premier dataset consitué des musiques de la playlist \"Top 10 000 songs of All-Time\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_playlists_data_to_csv(['1G8IpkZKobrIlXcVPoSIuf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1.b. Collecte du genre de la playlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons réussi à enregistrer une première version de notre df que nous visualiserons en partie I. 2. Cependant, cette approche ne nous donne que le genre de l'artiste et pas nécessairement de la playlist. C'est pourquoi nous avons décidé d'adapter certaines de nos fonctions afin de collecter le genre des playlists et de collecter les données de playlists aux genres spécifiques. Le genre de la playlist sera ensuite assimilé à celui de l'artiste. A cet effet, nous avons ajouté la fonction get_playlist_data_to_csv_with_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlists_data_to_csv_with_genre(playlist_ids):\n",
    "    \"\"\"This function allows to fetch the data from different playlists into a csv \n",
    "    Params:\n",
    "        - playlist_ids: a dict whose keys are genres and values are playlists (strings)\n",
    "    \"\"\"\n",
    "    names=[]\n",
    "    track_data=[]\n",
    "    file_name=''\n",
    "    for key in playlist_ids.keys(): \n",
    "        print(f\"Fetching playlist {playlist_ids[key]} tracks...\")\n",
    "        tracks = fetch_playlist_tracks(playlist_ids[key])\n",
    "        print(\"Fetching track data...\")\n",
    "        track_data+=(fetch_track_data_without_genre(tracks, key))\n",
    "    for key1 in playlist_ids.keys():\n",
    "        names.append(spotify_client().playlist(playlist_ids[key1])['name'])\n",
    "    for name in names:\n",
    "        file_name+=name+'+'\n",
    "    file_name=file_name[:-1]\n",
    "    print(file_name)\n",
    "    if track_data:\n",
    "        save_to_csv(track_data, f\"playlists_{file_name}_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Détaillons les fonctions appelées par cette fonction.fetch_track_data_without_genre permet d'obtenir les données d'une liste de chansons dont le genre est déjà connu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_track_data_without_genre(tracks,genre):\n",
    "    \"\"\"\n",
    "    Fetch metadata and audio features for each track in the playlist knowing the genre of the playlist\n",
    "    Params:\n",
    "        -tracks: List of tracks from the playlist.\n",
    "    Returns a list of dictionaries containing track metadata and audio features.\n",
    "    \"\"\"\n",
    "    track_data = []\n",
    "    i=0\n",
    "    for track in tracks:\n",
    "        track_id = track['id']\n",
    "        i+=1\n",
    "        audio_features = spotify_client().audio_features([track_id])[0]\n",
    "        if audio_features:  # Ensure audio features are available\n",
    "            artist_name = \", \".join([artist['name'] for artist in track['artists']])\n",
    "            dict_track={\"track Name\": track['name'],\n",
    "                \"artists\": artist_name,\n",
    "                \"track_id\": track_id,\n",
    "                \"popularity\": track['popularity'],\n",
    "                \"duration_ms\": track['duration_ms'],\n",
    "                \"explicit\": track['explicit'], 'genre': genre}\n",
    "            for key in audio_features.keys():\n",
    "                dict_track[key]=audio_features[key]\n",
    "            track_data.append(dict_track)\n",
    "        if i==100:\n",
    "            j+=1\n",
    "            save_to_csv(track_data, f\"intermédiaire_realdb{j}\")\n",
    "            i=0\n",
    "            time.sleep(60)\n",
    "    return track_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le genre est déjà connu car il s'agit de la clé utilisée lors des requêtes faites à la fonction get_playlist_data_to_csv_with_genre. Voici un exemple de requête:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_playlists_data_to_csv_with_genre({'rap' : '4KsrGBWG6gzBwGe9dx16OE', \n",
    "#                                      'country' : '33mU9g6y8nKFAOyiISor0G',\n",
    "#                                      'blues' : '7BDUphylF8dfPKFo9Tvdr9',\n",
    "#                                      'metal' : '1yYEy4MtNLVScj74wcPR7w',\n",
    "#                                      'r_and_b' : '7CI3NR7rvCkgiLhch1qprf',\n",
    "#                                      'classical_music' : '5n9btvMZ52rxwozhQdKU7v',\n",
    "#                                      'jazz' : '79Bcltku1dcD08JcAM29kL',\n",
    "#                                      'pop' : '7gqtGYFoCR3tAqTtEUQZTw'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette deuxième approche nous aurait permis de constituer un dataset plus précis mais nous n'avons pas pu la mettre en place. En effet, les conditions d'utilisation de l'API spotify ont été changées et il n'est plus possible de faire des requêtes donnant accès aux métadonnées des chansons. Notre Machine Learning utilisera donc un dataset Kaggle. Néanmoins, nous pouvons visualiser les données collectées en partie I.1.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.2. Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importons les modulees nécessaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouverture de la base de données sous forme de Dataframe pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/ponte/Projet_data/first_db.csv\"\n",
    "\n",
    "df = pd.read_csv(\"https://minio.lab.sspcloud.fr\" + file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2.a. Pré-Nettoyage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On supprime les colonnes de la database servant uniquement à identifier les musiques:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['track Name','track_id','type','id','uri','track_href', 'analysis_url'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble qu'il y ait de nombreux genres musicaux qui en réalité pourraient être considérés comme des sous-genres, nous allons donc les regrouper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres=df['genre'].unique().tolist()\n",
    "print(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    \"rap\": [\n",
    "        'hip hop', 'rap', 'dirty south rap', 'melodic rap', 'conscious hip hop', 'alternative hip hop', 'chicago rap', \n",
    "        'bronx hip hop', 'detroit hip hop', 'gangster rap', 'canadian hip hop', 'atl hip hop', 'lgbtq+ hip hop', 'bboy', 'hip pop'\n",
    "    ],\n",
    "    \"rock\": [\n",
    "        'classic rock', 'album rock', 'alternative rock', 'dance rock', 'hard rock', 'soft rock', 'irish rock', 'piano rock', \n",
    "        'australian rock', 'detroit rock', 'british blues', 'garage rock', 'classic garage rock', 'glam rock', 'art rock', \n",
    "        'alternative metal', 'folk rock', 'country rock', 'protopunk', 'space rock', 'experimental rock', 'modern rock', \n",
    "        'surf music', 'pub rock', 'new wave', 'dance-punk'\n",
    "    ],\n",
    "    \"pop\": [\n",
    "        'pop', 'dance pop', 'pop rock', 'ambient pop', 'alternative pop', 'bedroom pop', 'canadian pop', 'british soul', \n",
    "        'classic country pop', 'barbadian pop', 'bubblegum pop', 'torch song', 'french shoegaze', 'new wave pop', \n",
    "        'brill building pop', 'beatlesque', 'britpop', 'art pop', 'candy pop','power pop','electropop', 'experimental pop'\n",
    "    ],\n",
    "    \"blues\": [\n",
    "        'blues', 'blues rock', 'classic soul', 'r&b', 'british blues', \n",
    "        'louisiana blues', 'acoustic blues'\n",
    "    ],\n",
    "    \"jazz\":['cool jazz', 'bebop', \n",
    "        'avant-garde jazz', 'big band', 'hot jazz', 'jazz blues', 'gospel', 'soul jazz'],\n",
    "    \"country\": [\n",
    "        'folk', 'american folk revival', 'appalachian folk', 'ambient folk', 'bluegrass', 'bluegrass gospel', 'celtic punk', \n",
    "        'country', 'country rock', 'bakersfield sound', 'arkansas country', 'cowboy western', 'alternative americana'\n",
    "    ],\n",
    "    \"electro\": [\n",
    "        'edm', 'house', 'acid house', 'ambient', 'ambient house', 'ambient pop', 'dance-punk', 'electro', 'indietronica', \n",
    "        'balearic', 'atmospheric dnb', 'filter house', 'hi-nrg', 'big beat'\n",
    "    ],\n",
    "    \"classical\": [\n",
    "        'african-american classical', 'baroque pop', 'torch song', 'classic soundtrack', 'adult standards'\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_category(genre):\n",
    "    for category, keywords in categories.items():\n",
    "        if genre in keywords:\n",
    "            return category\n",
    "        elif genre=='N/A':\n",
    "            return \n",
    "    return \"other\"\n",
    "\n",
    "df[\"category\"] = df[\"genre\"].apply(assign_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2.b Visualisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysons tout d'abord les variables catégoriques de notre dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_var = df.copy().select_dtypes(include=[\"object\"]).columns.to_list()\n",
    "categorical_var.extend([\"key\",\"mode\",\"time_signature\",\"explicit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical_var].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les variables avec un faible nombre de valeurs différentes, nous allons les représenter sous forme d'histogramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_barplot = df[[\"explicit\",\"category\",\"mode\",\"time_signature\",\"key\"]].copy()\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "for c,var in enumerate(df_barplot.columns):\n",
    "  # compute frequency of each unique value\n",
    "  df_plot= df_barplot[var].value_counts(normalize=True).to_frame(\"frequency\").reset_index(names=var)\n",
    "  df_plot[\"frequency\"] = df_plot[\"frequency\"]*100\n",
    "\n",
    "  # plot the barplot\n",
    "  plt.subplot(3,2,c+1)\n",
    "  sns.barplot(data=df_plot, x=var, y=\"frequency\")\n",
    "  plt.title(str(var))\n",
    "  plt.xlabel(\"\")\n",
    "  plt.ylabel(\"\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous observons que la catégorie qui est le regroupement du genre est très mal répartie, cela risque de poser problème pour notre modèle car il s'agit de la variable cible qui devrait donc être répartie de façon uniforme afin de ne pas créer de biais dans notre modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les colonnes 'artists' et 'genre' nous allons visualiser le top10 des artistes les plus représentés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart for 'artists'\n",
    "artist_counts = df['artists'].value_counts().head(10) \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.pie(artist_counts, labels=artist_counts.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Top 10 Artists Distribution')\n",
    "plt.axis('equal')  \n",
    "plt.show()\n",
    "\n",
    "# Pie chart for 'genre'\n",
    "genre_counts = df['genre'].value_counts().head(10)  \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.pie(genre_counts, labels=genre_counts.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Top 10 Genres Distribution')\n",
    "plt.axis('equal')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même, la répartition des genres dans notre dataset n'est pas adaptée à notre problématique. Nous avons donc tenté l'approche détaillée en partie I.1.b. qui s'est avérée infructueuse du fait d'un changement de la politique de Spotify https://developer.spotify.com/blog/2024-11-27-changes-to-the-web-api nous allons donc, pour la suite utiliser un dataset de 30 000 musiques issu du site Kaggle https://www.kaggle.com/datasets/joebeachcapital/30000-spotify-songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Prédiction à l'aide d'une base de données Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.1. Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Dans cette partie nous allons nous occuper du preprocess c'est à dire du nettoyage et de la mise en forme des données en vue de la création du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des modules nécessaires : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/tlaflotte/genre_detector/spotify_tracks.csv\"\n",
    "\n",
    "df = pd.read_csv(\"https://minio.lab.sspcloud.fr\" + file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par éliminer toutes les colonnes qui contiennent des noms et des identifiants et qui n'apportent donc aucune information intéressante pour notre étude. Nous choisissons aussi de supprimer la colonne popularity car celle-ci est calculée de façon très obscure et comporte de trop nombreuses valeurs nulles pour les imputer alors même que les chansons sont célèbres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"track_name\",\"track_id\",\"track_artist\",\"track_album_id\",\"track_album_name\",\"track_album_release_date\",\n",
    "       \"playlist_name\", \"playlist_id\",\"track_popularity\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1.a Gestion des valeurs aberrantes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'abord, on va s'occuper des outliers. On va les identifier avec la méthode du z-score en considérant comme outliers les valeurs ayant un Zscore en valeur absolue supérieur à 3. On peut se permettre cela car les distributions de la plupart des variables sont proches de gaussiennes (voir-ci dessous), même si certaines variables font exceptions notamment tempo, valence et track_popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_var = [\n",
    "       'danceability', 'energy', 'loudness', 'speechiness',\n",
    "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
    "       'duration_ms']\n",
    "plt.figure(figsize=(10,12))\n",
    "\n",
    "for c,var in enumerate(continuous_var):\n",
    "  plt.subplot(6,2,c+1)\n",
    "  sns.kdeplot(data=df[continuous_var], x=var, fill=var)\n",
    "  plt.title(str(var))\n",
    "  plt.xlabel(\"\")\n",
    "  plt.ylabel(\"\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_outliers_zscore(df, threshold=3):\n",
    "    \"\"\"\n",
    "    Compte le nombre d'outliers dans chaque colonne continue d'un DataFrame selon la méthode Z-Score.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Le DataFrame contenant les colonnes continues.\n",
    "    - threshold (float): Seuil pour considérer une valeur comme outlier (par défaut : 3).\n",
    "\n",
    "    Returns:\n",
    "    - pd.Series: Série avec le nombre d'outliers pour chaque colonne.\n",
    "    \"\"\"\n",
    "    outlier_counts = {}\n",
    "    for column in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):  # Vérifie que la colonne est numérique\n",
    "            z_scores = zscore(df[column])\n",
    "            outliers = np.abs(z_scores) > threshold\n",
    "            outlier_counts[column] = np.sum(outliers)\n",
    "\n",
    "    return pd.Series(outlier_counts)\n",
    "\n",
    "# Compter les outliers\n",
    "outliers_zscore = count_outliers_zscore(df)\n",
    "\n",
    "count_outliers_zscore(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On identifie un petit nombre d'outliers et rien ne nous indique que ces valeurs sont absurdes ou fausses et non juste des valeurs qui sortent un peu de l'ordinaire. Ainsi plutôt que de supprimer les lignes en question, on va plutôt winsorizer les valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize_outliers(df, columns, threshold=3):\n",
    "    \"\"\"\n",
    "    Winsorise les valeurs aberrantes (outliers) dans les colonnes continues d'un DataFrame,\n",
    "    sans modifier le DataFrame original.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame contenant les colonnes continues.\n",
    "    - columns (list): Liste des colonnes à traiter.\n",
    "    - threshold (float): Seuil z-score pour définir les outliers.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Nouveau DataFrame avec les colonnes ajustées.\n",
    "    \"\"\"\n",
    "    # Créer une copie du DataFrame pour ne pas modifier l'original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    for column in columns:\n",
    "        z_scores = zscore(df_copy[column])\n",
    "        \n",
    "        # Calcul des limites\n",
    "        lower_bound = df_copy[column][z_scores > -threshold].min()\n",
    "        upper_bound = df_copy[column][z_scores < threshold].max()\n",
    "        \n",
    "        # Winsorisation\n",
    "        df_copy[column] = np.clip(df_copy[column], lower_bound, upper_bound)\n",
    "        \n",
    "    return df_copy\n",
    "\n",
    "df_winsorized = winsorize_outliers(df, ['danceability', 'energy', 'loudness', 'speechiness',\n",
    "       'acousticness', 'instrumentalness', 'liveness', 'tempo','duration_ms'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winsorized.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque ainsi que certaines valeurs extrêmes ont été modifiées, sans que les statistiques les plus basiques (moyenne, variance, médiane et quartiles) ne soient significativement impactées. On peut donc remplacer notre tableau par ce nouveau tableau winsorisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_winsorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1.b Standardisation des variables continues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_standardize = ['danceability', 'energy', 'loudness', 'speechiness',\n",
    "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
    "        'duration_ms']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_standardized = df.copy()\n",
    "df_standardized[columns_to_standardize] = scaler.fit_transform(df_standardized[columns_to_standardize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions désormais que les colonnes de df_standardized sont bel et bien standardisées, avant de remplacer df par ce nouveau\n",
    "tableau "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,12))\n",
    "\n",
    "for c,var in enumerate(continuous_var):\n",
    "  plt.subplot(6,2,c+1)\n",
    "  sns.kdeplot(data=df_standardized[continuous_var], x=var, fill=var)\n",
    "  plt.title(str(var))\n",
    "  plt.xlabel(\"\")\n",
    "  plt.ylabel(\"\")\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculons plutôt la moyenne et la variance des colonnes standardisées\n",
    "for col in columns_to_standardize:\n",
    "    mean = df_standardized[col].mean()\n",
    "    variance = df_standardized[col].var()\n",
    "    print(f\"Variable : {col}\")\n",
    "    print(f\"Moyenne : {mean:.6f}\")\n",
    "    print(f\"Variance : {variance:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les courbes ont bien changées mais visuellement il est difficile de dire que la standardisation a été correctement effectuée. En revanche, les calculs de moyenne et de variance ne laissent pas de doute, la standardisation est réussie. On peut donc remplacer df par notre nouveau tableau aux variables continues standardisées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1.c Imputation des valeur manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous devons imputer les valeurs manquantes dans 2 colonnes : liveness et valence. Nous allons pour cela comparer 3 modèles, la régression linéaire, random forest et Xgboost. \n",
    "Ainsi, pour notre comparaison, pour chaque modèle nous allons faire un test (en divisant notre jeu de données), et alors nous calculerons à la fois :\n",
    "- La MAE (Erreur absolue Moyenne) qui mesure la moyenne des écarts absolus entre les valeurs prédites par le modèle et les valeurs réélles\n",
    "- Le R2 (Coefficient de détermination) mesurant la proportion de variance des données expliquée par le modèle.\n",
    "Les résultats vont nous permettre de savoir quel modèle est le plus performants entre les 3. C'est avec ce modèle que nous ferons donc la prédiction des valeurs manquantes dans les colonnes liveness et tempo\n",
    "Nous allons naïvement utiliser toutes les autres variables (à l'exception de playlist-genre et playlist_subgenre) comme variables prédictives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [ 'speechiness', 'instrumentalness', 'energy', 'danceability', 'acousticness', 'tempo', \n",
    "              'duration_ms', 'loudness', 'key', 'mode']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec une régression linéaire : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_with_linear_regression(df, target_column, predictors, test_size=0.2):\n",
    "    clean_data = df[df[target_column].notna()]\n",
    "    X = clean_data[predictors]\n",
    "    y = clean_data[target_column]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"{target_column} - MAE : {mae:.4f}, R^2 : {r2:.4f}\")\n",
    "\n",
    "impute_with_linear_regression(df, 'liveness', predictors)\n",
    "\n",
    "impute_with_linear_regression(df, 'valence', predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats ne sont pas satisfaisants, les erreurs moyennes absolues sont assez éloignées de 1 et les coefficients de détermination sont faibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec random forest : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_with_random_forest(df, target_column, predictors, random_state=42):\n",
    "    \"\"\"\n",
    "    Impute les valeurs manquantes d'une colonne avec un Random Forest Regressor.\n",
    "\n",
    "    Arguments :\n",
    "    - df : DataFrame pandas\n",
    "    - target_column : Nom de la colonne cible à imputer\n",
    "    - predictors : Liste des colonnes à utiliser comme prédicteurs\n",
    "    - random_state : sert à la reproductibilité\n",
    "\n",
    "    Retourne :\n",
    "    - DataFrame avec les valeurs imputées pour la colonne cible\n",
    "    \"\"\"\n",
    "    df_rf = df.copy()\n",
    "    \n",
    "    train_data = df_rf[df_rf[target_column].notna()]\n",
    "    test_data = df_rf[df_rf[target_column].isna()]\n",
    "\n",
    "    if test_data.empty:\n",
    "        return df_rf\n",
    "\n",
    "    X_train = train_data[predictors]\n",
    "    y_train = train_data[target_column]\n",
    "\n",
    "    X_test = test_data[predictors]\n",
    "\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=random_state)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    predicted_values = rf_model.predict(X_test)\n",
    "\n",
    "    df_rf.loc[df[target_column].isna(), target_column] = predicted_values\n",
    "\n",
    "    return df_rf\n",
    "\n",
    "\n",
    "df_intermediary = impute_with_random_forest(df, target_column='liveness', predictors=predictors)\n",
    "\n",
    "df_rf = impute_with_random_forest(df_intermediary, target_column='valence', predictors=predictors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_random_forest_imputation(df, target_column, predictors, missing_rate=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Teste la validité de l'imputation avec un Random Forest Regressor.\n",
    "\n",
    "    Arguments :\n",
    "    - df : DataFrame pandas original\n",
    "    - target_column : Nom de la colonne cible\n",
    "    - predictors : Liste des colonnes à utiliser comme prédicteurs\n",
    "    - missing_rate : Proportion des données à masquer pour le test\n",
    "    - random_state : Seed pour la reproductibilité\n",
    "\n",
    "    Retourne :\n",
    "    - MAE : Erreur absolue moyenne entre les vraies et les valeurs imputées\n",
    "    - R^2 : Coefficient de détermination des valeurs imputées\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    non_missing_indices = df_copy[target_column].dropna().index\n",
    "    n_missing = int(missing_rate * len(non_missing_indices))\n",
    "    missing_indices = np.random.choice(non_missing_indices, n_missing, replace=False)\n",
    "\n",
    "    true_values = df_copy.loc[missing_indices, target_column]\n",
    "    df_copy.loc[missing_indices, target_column] = np.nan\n",
    "\n",
    "    df_rf = impute_with_random_forest(df_copy, target_column, predictors)\n",
    "\n",
    "    imputed_values = df_rf.loc[missing_indices, target_column]\n",
    "\n",
    "    mae = mean_absolute_error(true_values, imputed_values)\n",
    "    r2 = r2_score(true_values, imputed_values)\n",
    "\n",
    "    return mae, r2\n",
    "\n",
    "mae_liveness, r2_liveness = test_random_forest_imputation(df, target_column='liveness', predictors=predictors)\n",
    "print(f\"Liveness - MAE : {mae_liveness:.4f}, R^2 : {r2_liveness:.4f}\")\n",
    "\n",
    "mae_valence, r2_valence = test_random_forest_imputation(df, target_column='valence', predictors=predictors)\n",
    "print(f\"Valence - MAE : {mae_valence:.4f}, R^2 : {r2_valence:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs, quoique loin d'être parfaites, sont déjà plus satisfaisantes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avec xgboost : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_with_xgboost(df, target_col, predictors, test_size=0.2, random_state=42):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    train_data = df_copy[df_copy[target_col].notna()]\n",
    "    test_data = df_copy[df_copy[target_col].isna()]\n",
    "\n",
    "    if test_data.empty:\n",
    "        print(f\"No missing values in {target_col}.\")\n",
    "        return df_copy, None\n",
    "\n",
    "    X = train_data[predictors]\n",
    "    y = train_data[target_col]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=random_state)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    X_test = test_data[predictors]\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "    df_copy.loc[test_data.index, target_col] = y_pred\n",
    "\n",
    "    return df_copy, xgb_model\n",
    "\n",
    "df_intermediary_xg, liveness_model = impute_with_xgboost(df, target_col='liveness', predictors=predictors)\n",
    "\n",
    "df_xg, valence_model = impute_with_xgboost(df_intermediary_xg, target_col='valence', predictors=predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_xgboost_model(df, model, target_col, predictors):\n",
    "    \"\"\"\n",
    "    Évalue les performances du modèle XGBoost sur une colonne cible.\n",
    "    Retourne la MAE et le R^2.\n",
    "    \"\"\"\n",
    "    valid_data = df[df[target_col].notna()]\n",
    "    X = valid_data[predictors]\n",
    "    y_true = valid_data[target_col]\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return mae, r2\n",
    "\n",
    "mae_liveness, r2_liveness = evaluate_xgboost_model(df_intermediary_xg, liveness_model, 'liveness', predictors)\n",
    "print(f\"Liveness - MAE: {mae_liveness:.4f}, R^2: {r2_liveness:.4f}\")\n",
    "\n",
    "mae_valence, r2_valence = evaluate_xgboost_model(df_xg, valence_model, 'valence', predictors)\n",
    "print(f\"Valence - MAE: {mae_valence:.4f}, R^2: {r2_valence:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs sont encore une fois décevantes, et moins satisfaisantes encore qu'avec random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi, en se basant sur le R2 et la MAE c'est avec le random forest que l'on obtient les meilleures résultats c'est à dire les plus petites MAE et les plus grands R2. C'est donc avec ce modèle qu'on va imputer les NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1.d Imputation des variables catégorielles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_var = ['playlist_genre', 'playlist_subgenre', 'key', 'mode']\n",
    "df[categorical_var].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='playlist_subgenre', data=df)\n",
    "plt.title('Répartition des catégories de subgenre')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['playlist_subgenre'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les subgenre ont tous des proportions différentes, on peut ainsi les encoder en créant une nouvelle colonne playlist_subgenre_encoded qui contient la proportion du subgenre dans le dataset, cette colonne permet d'identifier le subgenre, on peut donc supprimer lea colonne subgenre. On a désormais des valeurs numériques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = df.copy()\n",
    "\n",
    "subgenre_proportions = df_encoded['playlist_subgenre'].value_counts(normalize=True)\n",
    "df_encoded['playlist_subgenre_encoded'] = df_encoded['playlist_subgenre'].map(subgenre_proportions)\n",
    "df_encoded = df_encoded.drop(columns=['playlist_subgenre'])\n",
    "\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le tableau df ne possède désormais plus de valeurs aberrantes (selon la méthode avec les Zscore que l'on a utilisé), les variables continues ont été standardisées. De plus, les valeurs manquantes ont été standardisées et la variables catégorielle playlist_subgenre a été encodée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code suivant permet de sauvegarder le nouveau dataframe en format csv, il est ainsi possible de le télécharger et de l'enregistrer sur onyxia : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('data_tracks_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.2. Réduction des features préparées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour faciliter la lecture de ce notebook nous importons directement le fichier préparé à l'aide de la partie précédent, notamment pour éviter le temps computationnel lié au machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/ponte/Projet_data/data_tracks_cleaned.csv\"\n",
    "\n",
    "df = pd.read_csv(\"https://minio.lab.sspcloud.fr\" + file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2.a. Analyse multivariée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_vars=['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "categorical_vars=['key', 'mode',  'playlist_genre', 'playlist_subgenre_encoded']\n",
    "\n",
    "df[categorical_vars] = df[categorical_vars].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons tout d'abord par observer la matrice des corrélations pour nos variables continues. Cela pourrait permettre d'éliminer des variables fortement corrélées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(df[continuous_vars].corr(),annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La corrélation la plus forte que nous observons est entre `energy` et `acousticness`. Celle-ci est de -0.53, ce chiffre est assez élevé et pourrait nous permettre de laisser de côté l'une de ces deux colonnes, néanmoins nous choisissons de la garder. En effet, normalement on considère qu'un colonne peut être supprimer si la corrélation est supérieure  à 0.8. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mieux visualiser les écarts entre les différentes variables dans la prédiction du genree, nous allons tracer des boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 40))\n",
    "\n",
    "for i, var in enumerate(continuous_vars):\n",
    "    plt.subplot(6, 2, i+1)\n",
    "    sns.boxplot(x='playlist_genre', y=var, data=df)\n",
    "    plt.title(f'Boxplot of {var} by Genre')\n",
    "    plt.xlabel('Decoded Genre')\n",
    "    plt.ylabel(var)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(continuous_vars),sharex=True, figsize=(10,20))\n",
    "\n",
    "for ax, var in zip(axes, continuous_vars):\n",
    "  sns.kdeplot(data=df, x=var, hue=\"playlist_genre\", fill=\"playlist_genre\",ax=ax);\n",
    "  ax.set_title(var)\n",
    "  ax.set_xlabel(\"\")\n",
    "  ax.set_ylabel(\"\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Le niveau de `danceability` est assez élevé pour les genres EDM et Latin. A l'inverse, le genre Rock semble avoir une médiane plus basse, indiquant que les chansons rock sont globalement moins dansantes. Les genres Pop, Rap et R&B montrent une distribution similaire avec une médiane modérée. Cela peut être dû au fait que ces dernières musiques sont des genres récents et que la frontière entre les genres est plus fine aujourd'hui.\n",
    "\n",
    "- `EDM` a l'énergie la plus élevée, avec une médiane haute une distribution très concentrée. C'est en effet un genre de musique très rythmé. `Rock`, `Rap` \n",
    "et `Latin` montrent également une bonne énergie, tandis que `Pop` et `R&B` ont des niveaux plus modérés. En effet, ce type de chansons est souvent plus calme.\n",
    "\n",
    "- `Rap` présente une valeur élevée de \"speechiness\", ce qui est attendu étant donné que ce genre repose beaucoup sur les paroles.\n",
    "\n",
    "- `EDM` et `Rock` sont les genres les plus bruyants ce qui est cohérent. La plage de valeurs est plus large pour `Pop` et `Rap`. Cela démontre que ces genres peuvent être parfois calmes et parfois plus énergiques, observation que l'on retrouvait sur la variable energy\n",
    "\n",
    "- `Rap` présente une valeur élevée de \"speechiness\", ce qui est attendu étant donné que ce genre repose beaucoup sur les paroles.\n",
    "\n",
    "- Les chansons de `R&B` et `Latin` sont souvent plus acoustiques. Alors que `EDM` est très électronique (valeur proche de 0 pour acousticness) ce qui fait sens.\n",
    "\n",
    "- la `liveness` est proche de 0 ce qui montre que les musiques sont quasiment toutes des versions studio\n",
    "\n",
    "En conclusion les genres musicaux semblent montrer des tendances claires dans leur répartition, par exemple:\n",
    "\n",
    "- EDM est énergique, rapide et souvent instrumental.\n",
    "- Rap se distingue par une \"speechiness\" élevée \n",
    "- Latin est dansant, joyeux, et acoustique.\n",
    "\n",
    "Ces tendances permettent d'identifier des différences claires entre les genres de musique ce qui nous permettra de mener à bien la classification lors de la phase de modélisation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2.b. Vérification du poids des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour vérifier si nous ne pourrions pas enlever des variables, nous allons mener une ACP et un random Forest simplement pour savoir le poids que ce modèle attribue à chaque variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca=df[continuous_vars]\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca.fit(df_pca)\n",
    "# Get the explained variance ratio\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "# Plot the explained variance ratio\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(explained_variance)), explained_variance, alpha=0.7, align='center')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Explained Variance Ratio by Principal Components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ACP ne nous permet pas de réduire notre dataframe à quelques composantes principales, en effet, les deux premières composantes n'incluent qu'une faible part d'explication de la variance. Cela se traduit aussi dans la part de chaque varible dans les composantes principales tracée ci-dessous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = pd.DataFrame(pca.components_, columns=df_pca.columns)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(components, annot=True, cmap='coolwarm', xticklabels=df_pca.columns, yticklabels=[f'PC{i+1}' for i in range(len(components))])\n",
    "plt.title(\"Contributions des variables aux composantes principales\")\n",
    "plt.xlabel(\"Variables\")\n",
    "plt.ylabel(\"Composantes principales\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de vérifier si des composantes qualitatives pourraient être supprimées, nous réalisons un random Forest pour évaluer le poids de chaque variable: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer les caractéristiques (features) et la cible (target)\n",
    "X = df.drop('playlist_genre', axis=1)\n",
    "y = df['playlist_genre']\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Extraire l'importance des variables\n",
    "importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Créer un DataFrame pour visualiser les importances\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Afficher les importances\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "playlist_subgenre_encoded occupe une importance forte, nous pourrions n'utiliser que cette variable pour notre étude. Cependant, cette variable contient en réalité l'information du genre, nous allons donc la supprimer du dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['playlist_subgenre_encoded'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer les caractéristiques (features) et la cible (target)\n",
    "X = df.drop('playlist_genre', axis=1)\n",
    "y = df['playlist_genre']\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Extraire l'importance des variables\n",
    "importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Créer un DataFrame pour visualiser les importances\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Afficher les importances\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pourrions supprimer certaines variables comme mode, key et liveness mais nous allons pour l'instant les garder dans notre modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.3. Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3.a. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, nous séparons la variable cible (le genre) des autres variables. Ensuite, nous divisons ces ensembles en deux parties : une pour entraîner le modèle et une autre pour le tester. Étant donné que notre jeu de données est organisé par genre, nous spécifions qu'il doit être divisé aléatoirement en utilisant l'argument `shuffle=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.copy()\n",
    "\n",
    "genres = np.array(features['playlist_genre'])\n",
    "features = features.drop(['playlist_genre'], axis = 1)\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "\n",
    "train_features, test_features, train_genres, test_genres = train_test_split(features, genres, test_size = 0.2, random_state = 0, shuffle = True)\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Genres Shape:', train_genres.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Genres Shape:', test_genres.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour optimiser les performances de nos modèles, nous effectuons un ajustement des hyperparamètres. Cette étape vise à trouver la meilleure combinaison de paramètres permettant de maximiser la précision du modèle sur l'ensemble de test.  \n",
    "\n",
    "Il existe en effet un très grand nombre d'hyperparamètres à ajuster. Pour simplifier les choses, nous nous concentrons sur les trois hyperparamètres clés suivants :  \n",
    "\n",
    "1. **Nombre d'arbres** (*n_estimators*) : Contrôle le nombre d'arbres dans l'ensemble.  \n",
    "2. **Profondeur maximale des arbres** (*max_depth*) : Détermine la profondeur maximale de chaque arbre.  \n",
    "3. **Nombre minimum d'échantillons par nœud** (*min_child_samples* ou *min_samples_split*) : Spécifie le nombre minimum d'échantillons requis dans un nœud pour permettre une division supplémentaire.  \n",
    "\n",
    "Nous n'avons pas spécifié de poids pour chaque genre, car le jeu de données est relativement équilibré. Cependant, pour améliorer encore le modèle, nous pourrions attribuer des poids à chaque genre afin de simuler un jeu de données parfaitement équilibré.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [1000, 2000, 4000]\n",
    "max_depth = [20,None]\n",
    "min_samples_split = [2, 4]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "              }\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous effectuons une recherche aléatoire en utilisant ces hyperparamètres et classons les différentes combinaisons en fonction de leur précision un GridSearch pourrait prendre trop de temps de calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of the model\n",
    "rf = RandomForestClassifier(random_state = 0, max_features = 'sqrt', bootstrap = True)\n",
    "\n",
    "# random search\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 12, cv = 3, verbose=2, random_state=0, n_jobs = -1)\n",
    "\n",
    "# fit\n",
    "rf_random.fit(train_features, train_genres)\n",
    "\n",
    "pd_res = pd.concat([pd.DataFrame(rf_random.cv_results_[\"params\"]),pd.DataFrame(rf_random.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)\n",
    "pd_res = pd_res.sort_values('Accuracy', ascending=False)\n",
    "print(rf_random.best_params_)\n",
    "print(pd_res.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous considérons donc que le modèle est le plus efficace avec un nombre d'arbres fixé à 4000 et max_depth à 20.A présent, nous allons faire tourner le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=4000, max_features='sqrt', max_depth=20, min_samples_split=2, min_samples_leaf=1, bootstrap=True, criterion='gini' ,random_state=0)\n",
    "\n",
    "rf.fit(train_features, train_genres)\n",
    "\n",
    "predictions = rf.predict(test_features)\n",
    "\n",
    "\n",
    "errors = zero_one_loss(test_genres, predictions, normalize=True)\n",
    "print('zero_one_loss error normalized:', errors)\n",
    "\n",
    "# Accuracy Score\n",
    "accuracy_test = accuracy_score(test_genres, predictions)\n",
    "print('accuracy_score on test dataset :', accuracy_test)\n",
    "\n",
    "print(classification_report(predictions, test_genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons une accuracy de 55,2% ce qui est satisfaisant. Toutefois, nous allons plotter la matrice de confusion pour visualiser les différentes erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(test_genres, predictions)\n",
    "plt.imshow(mat, cmap='viridis', interpolation='nearest')\n",
    "plt.title('Confusion matrix')\n",
    "num_rows, num_cols = mat.shape\n",
    "for i in range(num_rows):\n",
    "    for j in range(num_cols):\n",
    "        plt.text(j, i, str(mat[i, j]), ha='center', va='center', color='w', fontsize=12)\n",
    "plt.grid(False)\n",
    "genres_list = ['edm','latin','pop','r&b','rap','rock']\n",
    "plt.xticks(np.arange(num_cols), genres_list, rotation=45, ha='right')\n",
    "plt.yticks(np.arange(num_rows), genres_list)\n",
    "plt.xlabel('true genre')\n",
    "plt.ylabel('predicted genre')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous arrivons à bien prédire les genres rap, rock et edm et moins bien pop latin et r&b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importances\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "importances = list(rf.feature_importances_)\n",
    "\n",
    "x_values = list(range(len(importances)))\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous traçons l'importance de chaque caractéristique. Nous observons que les variables `key` et `mode` ne sont pas très utiles pour la prédiction. Cela est attendu, car ces variables varient relativement peu et ne sont pas fortement liées à chaque genre.  \n",
    "\n",
    "Ainsi, notre modèle Random Forest atteint une précision de 55,2 %, ce qui est satisfaisant. Cependant, il montre de mauvaises performances pour identifier les genres latin, pop et R&B, qui sont très répandus dans le monde musical, tandis qu'il excelle dans l'identification du genre edm, rap et rock. Cela semble logique car la frontière en latin, pop et r&b est parfois ténue et des morceaux peuvent être des hybrides entre deux genres. Cela est beaucoup moins le cas pour edm, rap et rock. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3.b XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de réaliser une modélisation avec XGBoost, il est nécessaire d'encoder nos variables, nous pourrions utiliser un module déjà implementé. Néanmoins, afin de conserver notre encodage et au vu de notre faible nombre de valeurs prises par notre variable cible, nous codons l'encodage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.copy()\n",
    "\n",
    "def genre_to_num(genre):\n",
    "    if genre == 'edm':\n",
    "        return 0\n",
    "    if genre == 'latin':\n",
    "        return 1\n",
    "    if genre == 'pop':\n",
    "        return 2\n",
    "    if genre == 'r&b':\n",
    "        return 3\n",
    "    if genre == 'rap':\n",
    "        return 4\n",
    "    if genre == 'rock':\n",
    "        return 5\n",
    "\n",
    "features['playlist_genre'] = features['playlist_genre'].apply(genre_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolation of the feature to predict\n",
    "genres = np.array(features['playlist_genre'])\n",
    "features = features.drop(['playlist_genre'], axis = 1)\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "\n",
    "# separation in training and testing sets\n",
    "train_features, test_features, train_genres, test_genres = train_test_split(features, genres, test_size = 0.25, random_state = 0, shuffle = True)\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Genres Shape:', train_genres.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Genres Shape:', test_genres.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons la même méthode que pour Random Forest afin de déterminer nos hyperparamètres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid = {\n",
    "    \"gamma\" : [0],\n",
    "    \"learning_rate\" : [0.1],\n",
    "    \"max_depth\" : [20, None],\n",
    "    \"n_estimators\" : [100, 200, 300, 400, 500], \n",
    "    \"subsample\" : [0.8]}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model creation\n",
    "clf = XGBClassifier(objective='multi:softprob', random_state=42)\n",
    "\n",
    "# Random search\n",
    "clf_random = RandomizedSearchCV(estimator=clf, param_distributions=random_grid, n_iter=10, cv=3, verbose=2, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "clf_random.fit(train_features, train_genres)\n",
    "\n",
    "pd_res = pd.concat([pd.DataFrame(clf_random.cv_results_[\"params\"]), pd.DataFrame(clf_random.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])], axis=1)\n",
    "pd_res = pd_res.sort_values('Accuracy', ascending=False)\n",
    "print(pd_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\" : [0.1], #d0.3\n",
    "    \"max_depth\"        : [20], #d6\n",
    "    \"n_estimators\" : [100, 200, 300], #d100\n",
    "    \"subsample\" : [0.8], #d1\n",
    "}\n",
    "\n",
    "pprint(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(objective= 'multi:softprob', random_state = 0)\n",
    "\n",
    "grid = GridSearchCV(clf, param_grid = param_grid, n_jobs=-1, scoring=\"accuracy\", cv=3) #scoring=\"neg_log_loss\"\n",
    "grid.fit(train_features, train_genres)\n",
    "\n",
    "pd_res = pd.concat([pd.DataFrame(grid.cv_results_[\"params\"]),pd.DataFrame(grid.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)\n",
    "pd_res = pd_res.sort_values('Accuracy', ascending=False)\n",
    "print(pd_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant entraîner le modèle avec 300 arbres, un learning rate de 0.1, une max_depth de 20 et subsample de 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = XGBClassifier(objective='multi:softprob', colsample_bylevel=1, colsample_bytree=1, \n",
    "                          gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=20, min_child_weight=1, \n",
    "                          n_estimators=300, subsample=0.8, random_state = 42)\n",
    "\n",
    "model_xgb.fit(train_features, train_genres)\n",
    "\n",
    "predict_test = model_xgb.predict(test_features)\n",
    " \n",
    "\n",
    "accuracy_test = accuracy_score(test_genres, predict_test)\n",
    "print('\\naccuracy_score on test dataset : ', accuracy_test)\n",
    "print(classification_report(predict_test, test_genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons une accuracy de 55,3% ce qui est très similaire à la random forest. Cependant, le temps de calcul est netemment plus rapide ce qui est intéressant du point de vue du coût computationnel. De plus, le modèle est beaucoup plus léger (quelques mégas contre quelqués gigas pour random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "mat = confusion_matrix(test_genres, predict_test)\n",
    "plt.imshow(mat, cmap='viridis', interpolation='nearest')\n",
    "plt.title('Confusion Matrix')\n",
    "num_rows, num_cols = mat.shape\n",
    "for i in range(num_rows):\n",
    "    for j in range(num_cols):\n",
    "        plt.text(j, i, str(mat[i, j]), ha='center', va='center', color='w', fontsize=12)\n",
    "plt.grid(False)\n",
    "genres_list = ['edm','latin','pop','r&b','rap','rock']\n",
    "plt.xticks(np.arange(num_cols), genres_list, rotation=45, ha='right')\n",
    "plt.yticks(np.arange(num_rows), genres_list)\n",
    "plt.xlabel('true genre')\n",
    "plt.ylabel('predicted genre')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme avec Random Forest, nous prédisons bien edm, rap et rock mais moins bien latin, pop et r&b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3.c. Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous appliquons la même méthode que précédemment pour préparer nos données et ajuster nos hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy features\n",
    "features = df.copy()\n",
    "\n",
    "# Isolate the target variable\n",
    "genres = np.array(features['playlist_genre'])\n",
    "features = features.drop(['playlist_genre'], axis = 1)\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "\n",
    "# Split into training and testing sets\n",
    "train_features, test_features, train_genres, test_genres = train_test_split(features, genres, test_size = 0.25, random_state = 0, shuffle = True)\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Genres Shape:', train_genres.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Genres Shape:', test_genres.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CatBoostClassifier model\n",
    "model = CatBoostClassifier(cat_features=[], iterations=1000, learning_rate=0.1, depth=6, verbose=0)\n",
    "\n",
    "# Hyperparameter tuning with RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'iterations': [500, 1000, 2000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'depth': [5, 6, 7, 8],\n",
    "    'l2_leaf_reg': [1, 3, 5],\n",
    "    'border_count': [32, 64, 128]\n",
    "}\n",
    "\n",
    "# Randomized search\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=12, cv=3, verbose=2, random_state=0, n_jobs=-1)\n",
    "random_search.fit(train_features, train_genres)\n",
    "\n",
    "# Display results of the search\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "\n",
    "# Detailed results\n",
    "pd_res = pd.concat([pd.DataFrame(random_search.cv_results_[\"params\"]),\n",
    "                    pd.DataFrame(random_search.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])], axis=1)\n",
    "pd_res = pd_res.sort_values('Accuracy', ascending=False)\n",
    "print(pd_res.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les paramètres choisis sont:\n",
    "- **Learning rate (learning_rate)**: 0.05\n",
    "- **L2 leaf regularization (l2_leaf_reg)**: 1\n",
    "- **Number of trees (iterations)**: 1000\n",
    "- **Depth (depth)**: 5\n",
    "- **Border count (border_count)**: 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(learning_rate=0.05,l2_leaf_reg=1,n_estimators=1000,depth=5,border_count=64, \n",
    "                           cat_features=[], verbose=0)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_features, train_genres)\n",
    "\n",
    "# Predictions\n",
    "predictions = model.predict(test_features)\n",
    "\n",
    "# Zero-One Loss Error\n",
    "errors = zero_one_loss(test_genres, predictions, normalize=True)\n",
    "print('Zero-One Loss error normalized:', errors)\n",
    "\n",
    "# Accuracy Score\n",
    "accuracy_test = accuracy_score(test_genres, predictions)\n",
    "print('Accuracy score on test dataset:', accuracy_test)\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(test_genres, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons une accuracy de 56% ce qui est proche des résultats précédents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "mat = confusion_matrix(test_genres, predictions)\n",
    "plt.imshow(mat, cmap='viridis', interpolation='nearest')\n",
    "plt.title('Confusion Matrix')\n",
    "num_rows, num_cols = mat.shape\n",
    "for i in range(num_rows):\n",
    "    for j in range(num_cols):\n",
    "        plt.text(j, i, str(mat[i, j]), ha='center', va='center', color='w', fontsize=12)\n",
    "plt.grid(False)\n",
    "genres_list = ['edm','latin','pop','r&b','rap','rock']\n",
    "plt.xticks(np.arange(num_cols), genres_list, rotation=45, ha='right')\n",
    "plt.yticks(np.arange(num_rows), genres_list)\n",
    "plt.xlabel('true genre')\n",
    "plt.ylabel('predicted genre')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encore une fois, les gens les mieux prédits sont edm, rap et rock et les moins bien prédits sont latin pop et r&b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "importances = list(model.feature_importances_)\n",
    "\n",
    "x_values = list(range(len(importances)))\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous observons un changement par rapport aux graphiques des deux modèles précédents. En effet, il semble que le modèle CatBoost s’appuie moins sur la variable \"liveness\" que les autres. Cependant, nous constatons toujours des similitudes, comme le fait que les variables \"key\" et \"mode\" n'ont que peu d’impact sur la prédiction du genre musical.  \n",
    "\n",
    "De plus, notre modèle CatBoost nous permet de prédire un genre musical avec une précision de 56 %, ce qui est plutôt satisfaisant. Néanmoins, il garde les mêmes erreurs de prédiction sur latin, r&b et pop que les deux autres modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons été en mesure de prédire le genre d'une musique à l'aide de quelques caractéristiques audio avec une précision de 56%. Ce résultat est encourageant au vu de la taille réduite de notre dataset d'entraînement.\n",
    "\n",
    "Nous avons testé trois modèles : Random Forest, XGBoost et CatBoost, qui ont tous donné des résultats similaires et globalement satisfaisants. Néanmoins, le coût temporel et spatial diffère fortement selon ces modèles. En effet, random forest occupe un espace et demande des calculs beaucoup plus importants que les deux autres. Ces approches seraient donc celles à prioriser.\n",
    "\n",
    "Une piste d'amélioration serait une meilleure prédiction des genres pop et R&B. Cependant, le principal défi de notre projet semble résider dans le fait que l'attribution d'un genre musical est intrinsèquement subjective, ce qui se reflète dans les caractéristiques communes des genres comme le pop et le R&B."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
