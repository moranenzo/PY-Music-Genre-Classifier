{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Dans ce notebook, nous allons nous occuper du preprocess c'est à dire du nettoyage et de la mise en forme des données en vue de la création du modèle. Cette partie n'est pas documentée et ne contient que le code qui sert proprement à la modification du dataframe pour le preprocess. Des détails et des explications sont données dans la partie correspondante (partie II) du notebook principal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/tlaflotte/genre_detector/spotify_tracks.csv\"\n",
    "\n",
    "df = pd.read_csv(\"https://minio.lab.sspcloud.fr\" + file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"track_name\",\"track_id\",\"track_artist\",\"track_album_id\",\"track_album_name\",\"track_album_release_date\",\n",
    "       \"playlist_name\", \"playlist_id\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize_outliers(df, columns, threshold=3):\n",
    "    \"\"\"\n",
    "    Winsorise les valeurs aberrantes (outliers) dans les colonnes continues d'un DataFrame,\n",
    "    sans modifier le DataFrame original.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame contenant les colonnes continues.\n",
    "    - columns (list): Liste des colonnes à traiter.\n",
    "    - threshold (float): Seuil z-score pour définir les outliers.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Nouveau DataFrame avec les colonnes ajustées.\n",
    "    \"\"\"\n",
    "    # Créer une copie du DataFrame pour ne pas modifier l'original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    for column in columns:\n",
    "        z_scores = zscore(df_copy[column])\n",
    "        \n",
    "        # Calcul des limites\n",
    "        lower_bound = df_copy[column][z_scores > -threshold].min()\n",
    "        upper_bound = df_copy[column][z_scores < threshold].max()\n",
    "        \n",
    "        # Winsorisation\n",
    "        df_copy[column] = np.clip(df_copy[column], lower_bound, upper_bound)\n",
    "        \n",
    "    return df_copy\n",
    "\n",
    "df_winsorized = winsorize_outliers(df, ['danceability', 'energy', 'loudness', 'speechiness',\n",
    "       'acousticness', 'instrumentalness', 'liveness', 'tempo','duration_ms'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_winsorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_standardize = ['track_popularity', 'danceability', 'energy', 'loudness', 'speechiness',\n",
    "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
    "        'duration_ms']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_standardized = df.copy()\n",
    "df_standardized[columns_to_standardize] = scaler.fit_transform(df_standardized[columns_to_standardize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['track_popularity', 'speechiness', 'instrumentalness', 'energy', 'danceability', 'acousticness', 'tempo', \n",
    "              'duration_ms', 'loudness', 'key', 'mode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_with_random_forest(df, target_column, predictors, random_state=42):\n",
    "    \"\"\"\n",
    "    Impute les valeurs manquantes d'une colonne avec un Random Forest Regressor.\n",
    "\n",
    "    Arguments :\n",
    "    - df : DataFrame pandas\n",
    "    - target_column : Nom de la colonne cible à imputer\n",
    "    - predictors : Liste des colonnes à utiliser comme prédicteurs\n",
    "    - random_state : sert à la reproductibilité\n",
    "\n",
    "    Retourne :\n",
    "    - DataFrame avec les valeurs imputées pour la colonne cible\n",
    "    \"\"\"\n",
    "    df_rf = df.copy()\n",
    "    \n",
    "    train_data = df_rf[df_rf[target_column].notna()]\n",
    "    test_data = df_rf[df_rf[target_column].isna()]\n",
    "\n",
    "    if test_data.empty:\n",
    "        return df_rf\n",
    "\n",
    "    X_train = train_data[predictors]\n",
    "    y_train = train_data[target_column]\n",
    "\n",
    "    X_test = test_data[predictors]\n",
    "\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=random_state)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    predicted_values = rf_model.predict(X_test)\n",
    "\n",
    "    df_rf.loc[df[target_column].isna(), target_column] = predicted_values\n",
    "\n",
    "    return df_rf\n",
    "\n",
    "\n",
    "df_intermediary = impute_with_random_forest(df, target_column='liveness', predictors=predictors)\n",
    "\n",
    "df_rf = impute_with_random_forest(df_intermediary, target_column='valence', predictors=predictors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgenre_proportions = df['playlist_subgenre'].value_counts(normalize=True)\n",
    "df['playlist_subgenre_encoded'] = df['playlist_subgenre'].map(subgenre_proportions)\n",
    "df = df.drop(columns=['playlist_subgenre'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
